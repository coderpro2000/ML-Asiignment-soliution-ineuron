{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Supervised learning algorithms are trained using labeled data. Unsupervised learning algorithms are trained using unlabeled data. ... In unsupervised learning, only input data is provided to the model. The goal of supervised learning is to train the model so that it can predict the output when it is given new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa596e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Below is the list of some popular unsupervised learning algorithms:\n",
    "K-means clustering.\n",
    "KNN (k-nearest neighbors)\n",
    "Hierarchal clustering.\n",
    "Anomaly detection.\n",
    "Neural Networks.\n",
    "Principle Component Analysis.\n",
    "Independent Component Analysis.\n",
    "Apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "What are types of clustering methods?\n",
    "The various types of clustering are:\n",
    "Connectivity-based Clustering (Hierarchical clustering)\n",
    "Centroids-based Clustering (Partitioning methods)\n",
    "Distribution-based Clustering.\n",
    "Density-based Clustering (Model-based methods)\n",
    "Fuzzy Clustering.\n",
    "Constraint-based (Supervised Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9961a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Every data point is allocated to each of the clusters through reducing the in-cluster sum of squares. In other words, the K-means algorithm identifies k number of centroids, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78cc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "K-means attempts to minimize the total squared error, while k-medoids minimizes the sum of dissimilarities between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k -means algorithm, k -medoids chooses datapoints as centers ( medoids or exemplars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dafbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "A dendrogram is a diagram that shows the attribute distances between each pair of sequentially merged classes. To avoid crossing lines, the diagram is graphically arranged so that members of each pair of classes to be merged are neighbors in the diagram. The Dendrogram tool uses a hierarchical clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22be053",
   "metadata": {},
   "outputs": [],
   "source": [
    "One of the method is known as elbow method. First of all compute the sum of squared error(SSE) for some value of K. SSE is defined as the sum of the squared distance between centroid and each member of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f039c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Introduction to K-Means Clustering\n",
    "Step 1: Choose the number of clusters k. ...\n",
    "Step 2: Select k random points from the data as centroids. ...\n",
    "Step 3: Assign all the points to the closest cluster centroid. ...\n",
    "Step 4: Recompute the centroids of newly formed clusters. ...\n",
    "Step 5: Repeat steps 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In single-link (or single linkage) hierarchical clustering, we merge in each step the two clusters whose two closest members have the smallest distance (or: the two clusters with the smallest minimum pairwise distance). ... This motivates the term complete-link clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50afedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apriori algorithm assumes that any subset of a frequent itemset must be frequent. Its the algorithm behind Market Basket Analysis. ... So, according to the principle of Apriori, if {Grapes, Apple, Mango} is frequent, then {Grapes, Mango} must also be frequent. Here is a dataset consisting of six transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d974b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284662f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
