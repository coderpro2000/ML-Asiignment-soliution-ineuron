{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f242aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "The slope indicates the steepness of a line and the intercept indicates the location where it intersects an axis. The slope and the intercept define the linear relationship between two variables, and can be used to estimate an average rate of change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Identify slope from a graph. ... Using two of the points on the line, you can find the slope of the line by finding the rise and the run. The vertical change between two points is called the rise, and the horizontal change is called the run. The slope equals the rise divided by the run: Slope =riserun Slope = rise run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51943ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "If the signs are different then the answer is negative! If the slope is negative you can plot your next point by going down and right OR up and left. f the slope is positive you can plot your next point by going up and right OR down and left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "If the signs are different then the answer is negative! If the slope is negative you can plot your next point by going down and right OR up and left. f the slope is positive you can plot your next point by going up and right OR down and left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33dd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "To find the maximum/minimum of a curve you must first differentiate the function and then equate it to zero. This gives you one coordinate. To find the other you must resubstitute the one already found into the original function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS: Ordinary Least Square Method\n",
    "Set a difference between dependent variable and its estimation:\n",
    "Square the difference:\n",
    "Take summation for all data.\n",
    "To get the parameters that make the sum of square difference become minimum, take partial derivative for each parameter and equate it with zero,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6babe0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A high standard error (relative to the coefficient) means either that 1) The coefficient is close to 0 or 2) The coefficient is not well estimated or some combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe690c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "As an example, an analyst may want to know how the movement of the market affects the price of ExxonMobil (XOM). In this case, their linear equation will have the value of the S&P 500 index as the independent variable, or predictor, and the price of XOM as the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are four assumptions associated with a linear regression model: Linearity: The relationship between X and the mean of Y is linear. Homoscedasticity: The variance of residual is the same for any value of X. Independence: Observations are independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nonconstant variance and weighted least squares. Autocorrelation and time series methods. Multicollinearity, which exists when two or more of the predictors in a regression model are moderately or highly correlated with one another. Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfbd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear regression improve accuracy\n",
    "8 Methods to Boost the Accuracy of a Model\n",
    "Add more data. Having more data is always a good idea. ...\n",
    "Treat missing and Outlier values. ...\n",
    "Feature Engineering. ...\n",
    "Feature Selection. ...\n",
    "Multiple algorithms. ...\n",
    "Algorithm Tuning. ...\n",
    "Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n statistics, polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x. ... For this reason, polynomial regression is considered to be a special case of multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set. ... Based on historical data about earlier outcomes involving the same input criteria, it then scores new cases on their probability of falling into a particular outcome category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba83939",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic assumptions that must be met for logistic regression include independence of errors, linearity in the logit for continuous variables, absence of multicollinearity, and lack of strongly influential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data. This is achieved by maximizing a likelihood function so that, under the assumed statistical model, the observed data is most probable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
