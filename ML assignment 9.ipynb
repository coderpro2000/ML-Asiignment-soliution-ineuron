{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af79a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is feature engineering, and how does it work? Explain the various aspects of feature\n",
    "engineering in depth.\n",
    " \n",
    "Basically, all machine learning algorithms use some input data to create outputs. This input data comprise features, which are usually in the form of structured columns. Algorithms require features with some specific characteristic to work properly. Here, the need for feature engineering arises. I think feature engineering efforts mainly have two goals:\n",
    "Preparing the proper input dataset, compatible with the machine learning algorithm requirements.\n",
    "Improving the performance of machine learning models.\n",
    "The features you use influence more than everything else the result. No algorithm alone, to my knowledge, can supplement the information gain given by correct feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998608a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is feature selection, and how does it work? What is the aim of it? What are the various\n",
    "methods of function selection?\n",
    "\n",
    "Feature Selection Methods. Feature selection methods are intended to reduce the number of input variables to those that are \n",
    "believed to be most useful to a model in order to predict the target variable. Feature selection is primarily focused on \n",
    "removing non-informative or redundant predictors from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceca08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Describe the function selection filter and wrapper approaches. State the pros and cons of each\n",
    "approach?\n",
    "\n",
    "Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure \n",
    "the usefulness of a subset of feature by actually training a model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948295d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Describe the overall feature selection process.\n",
    "\n",
    "Feature Selection is the process where you automatically or manually select those features which contribute most to your \n",
    "prediction variable or output in which you are interested in. Having irrelevant features in your data can decrease the accuracy\n",
    "of the models and make your model learn based on irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79336de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Describe the feature engineering process in the sense of a text categorization issue.\n",
    "\n",
    "\n",
    "Text classification is the problem of assigning categories to text data according to its content. The most important part of\n",
    "text classification is feature engineering: the process of creating features for a machine learning model from raw text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511fdaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of \n",
    "the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often\n",
    "used to measure document similarity in text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e05fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "State what is meant by &quot;high-dimensional data set&quot;? Could you offer a few real-life examples?\n",
    "What are the difficulties in using machine learning techniques on a data set with many dimensions?\n",
    "What can be done about it?\n",
    "\n",
    "\n",
    "High Dimensional means that the number of dimensions are staggeringly high â€” so high that calculations become extremely\n",
    "difficult. With high dimensional data, the number of features can exceed the number of observations. For example, microarrays,\n",
    "which measure gene expression, can contain tens of hundreds of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe7f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA is an acronym for Personal Computer Analysis.\n",
    "\n",
    "\n",
    "PCA: Commonly used abbreviation for patient-controlled analgesia. Analgesia simply means relief of pain. PCA is a method by\n",
    "    which the patient controls the amount of pain medicine (analgesia) they receive. There are a number of different PCA\n",
    "    systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedded methods combine the qualities' of filter and wrapper methods. It's implemented by algorithms that have their own\n",
    "built-in feature selection methods. Some of the most popular examples of these methods are LASSO and RIDGE regression which\n",
    "have inbuilt penalization functions to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22458d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image result for Sequential backward exclusion vs. sequential forward selection\n",
    "Forward Selection: Forward selection is an iterative method in which we start with having no feature in the model. ... Backward\n",
    "    Elimination: In backward elimination, we start with all the features and removes the least significant feature at each \n",
    "        iteration which improves the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dfad3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
