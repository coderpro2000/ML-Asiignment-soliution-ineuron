{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4040a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Before applying data to SVM, it is important to perform scaling of that data. Main purpose of scaling data before processing is to avoid attributes in greater numeric ranges. Other purpose is to avoid some types of numerical difficulties during calculation. Large attribute values might cause numerical problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf591d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "An SVM classifier can output the distance between the test instance and the decision boundary, and you can use this as a confidence score. However, this score cannot be directly converted into an estimation of the class probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28723e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "How many times we need to train our SVM model in such case? For a 4 class problem, you would have to train the SVM at least 4 times if you are using a one-vs-all method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80581c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RBF Kernel is popular because of its similarity to K-Nearest Neighborhood Algorithm. It has the advantages of K-NN and overcomes the space complexity problem as RBF Kernel Support Vector Machines just needs to store the support vectors during training and not the entire dataseimport numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Import Dataset\n",
    "dataset = pd.read_csv(\"../input/housing.csv\")\n",
    "dataset.head() # Print first 5 observations from dataset using head()\n",
    "longitude\tlatitude\thousing_median_age\ttotal_rooms\ttotal_bedrooms\tpopulation\thouseholds\tmedian_income\tocean_proximity\tmedian_house_value\n",
    "0\t-122.23\t37.88\t41\t880\t129.0\t322\t126\t8.3252\tNEAR BAY\t452600\n",
    "1\t-122.22\t37.86\t21\t7099\t1106.0\t2401\t1138\t8.3014\tNEAR BAY\t358500\n",
    "2\t-122.24\t37.85\t52\t1467\t190.0\t496\t177\t7.2574\tNEAR BAY\t352100\n",
    "3\t-122.25\t37.85\t52\t1274\t235.0\t558\t219\t5.6431\tNEAR BAY\t341300\n",
    "4\t-122.25\t37.85\t52\t1627\t280.0\t565\t259\t3.8462\tNEAR BAY\t342200\n",
    "# Check in which column contains nan values\n",
    "dataset.isnull().any()\n",
    "longitude             False\n",
    "latitude              False\n",
    "housing_median_age    False\n",
    "total_rooms           False\n",
    "total_bedrooms         True\n",
    "population            False\n",
    "households            False\n",
    "median_income         False\n",
    "ocean_proximity       False\n",
    "median_house_value    False\n",
    "dtype: bool\n",
    "\"total_bedrooms\" contains nan values sothat it is showing True\n",
    "\n",
    "# Separate features and labels\n",
    "features = dataset.iloc[:,:-1].values\n",
    "label = dataset.iloc[:,-1].values.reshape(-1,1)\n",
    "# Perform Imputation with strategy=mean\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputerNaN = Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "features[:,[4]] = imputerNaN.fit_transform(features[:,[4]])\n",
    "# Perform Label Encoding and Onehot Encding on categorical values present in the features\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "features[:,8] = LabelEncoder().fit_transform(features[:,8])\n",
    "features = OneHotEncoder(categorical_features=[8]).fit_transform(features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553eed44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f03220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e60c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a5ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4226091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361e3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
